{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c771e3ac",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook prepares data for subsequent analysis and modeling.\n",
    "\n",
    "**Inputs (loaded):**\n",
    "- `TriviaQAData/train_queries_trivia_qa.json`\n",
    "- `TriviaQAData/val_queries_trivia_qa.json`\n",
    "\n",
    "**Outputs (saved):**\n",
    "- Activation maps separated by MLP layers for each query correctly classified by the model.\n",
    "- Subsequent useful dictionaries filtering queries or doc-ids by desired properties, to be used later.\n",
    "\n",
    "**High-level steps:**\n",
    "1. Prepare queries data set.\n",
    "2. Collect correctly classified queries.\n",
    "3. Run model only on correct queries, while saving activations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from transformer_lens import HookedEncoderDecoder\n",
    "from transformer_lens.loading_from_pretrained import OFFICIAL_MODEL_NAMES\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6fb11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:20:54.863711600Z",
     "start_time": "2025-06-29T14:20:39.535698100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ye2RpUerr4im",
    "outputId": "a471cce3-9649-4aab-e289-3e36ac74b305"
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a773d",
   "metadata": {
    "id": "doufxfLpvbGN"
   },
   "source": [
    "## Loading the Model in TransformerLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b220c24",
   "metadata": {
    "id": "_QyxxC8cw0PF"
   },
   "source": [
    "Download the model first: https://cloud.anja.re/s/qckH8GQPyN6YK8w#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c78204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:25:41.252777600Z",
     "start_time": "2025-06-29T14:20:54.863711600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xCPM0GUr0d5",
    "outputId": "f20f953e-6efa-49c2-ef5d-5059bd2e4d4f"
   },
   "outputs": [],
   "source": [
    "checkpoint = 'DSI-large-TriviaQA'\n",
    "OFFICIAL_MODEL_NAMES.append(checkpoint)\n",
    "hf_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "device = utils.get_device()\n",
    "model = HookedEncoderDecoder.from_pretrained(checkpoint, hf_model=hf_model, device=device)\n",
    "tokenizer_t5 = AutoTokenizer.from_pretrained('google-t5/t5-large')\n",
    "first_added_doc_id = len(tokenizer_t5)\n",
    "last_added_doc_id = len(tokenizer_t5) + (len(tokenizer) - len(tokenizer_t5))\n",
    "del tokenizer_t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f49c7e",
   "metadata": {
    "id": "GXJ_CdZaveA2"
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9358f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:29:40.742447700Z",
     "start_time": "2025-06-29T14:29:39.589066900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjIsOKZ8Etj4",
    "outputId": "c2adca12-a9c3-4e43-9a27-33e2b46afb11"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 4\n",
    "with open('TriviaQAData/val_queries_trivia_qa.json', mode='r') as f:\n",
    "    val_data = json.load(f)\n",
    "with open('TriviaQAData/train_queries_trivia_qa.json', mode='r') as f:\n",
    "    train_data = json.load(f)\n",
    "data = val_data + train_data\n",
    "q_id_to_entry = {entry['id']: entry for entry in data}\n",
    "doc_id_to_entries = {}\n",
    "for entry in data:\n",
    "    for doc_id in entry['relevant_docs']:\n",
    "        doc_id_to_entries.setdefault(doc_id, []).append(entry)\n",
    "doc_id_to_entries = {doc_id: entries for doc_id, entries in doc_id_to_entries.items() if len(entries) >= THRESHOLD}\n",
    "filtered_entries_ids = set([entry['id'] for ent_list in doc_id_to_entries.values() for entry in ent_list])\n",
    "filtered_entries = [q_id_to_entry[id] for id in filtered_entries_ids]\n",
    "queries = [entry['query'] for entry in filtered_entries]\n",
    "ground_truths = [entry['relevant_docs'] for entry in filtered_entries]\n",
    "query_ids = [entry['id'] for entry in filtered_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31eb6ba",
   "metadata": {
    "collapsed": false,
    "id": "08kqLqFSGu6C"
   },
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31d5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T14:25:15.933143700Z",
     "start_time": "2025-06-28T14:25:15.933143700Z"
    },
    "id": "xFsHJbX3Gu6C"
   },
   "outputs": [],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, inputs, targets, ids):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.inputs[idx], self.targets[idx], self.ids[idx])\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input_texts, target_texts, ids = zip(*batch)\n",
    "        return (input_texts, target_texts, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cf819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T14:25:18.738615Z",
     "start_time": "2025-06-28T14:25:18.705083Z"
    },
    "id": "qr1kBDDjGu6C"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = QuestionsDataset(queries, ground_truths, query_ids)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41a1a7",
   "metadata": {},
   "source": [
    "### Finding Correct Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f2cd1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-28T14:40:25.779277300Z"
    },
    "id": "ze0zB9tkGAvn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "decoder_input = torch.tensor([[0]])\n",
    "doc_id_to_valid_queries = {}\n",
    "queries_to_correct_predicted_ids = {}\n",
    "for input_texts, target_texts, ids in data_loader:\n",
    "    input_tokens = tokenizer(input_texts, return_tensors='pt', padding=True)['input_ids']\n",
    "    logits = model.forward(input_tokens, decoder_input)\n",
    "    res = tokenizer.decode(torch.topk(logits, K, dim=-1)[1].flatten())\n",
    "    doc_ids = [s for s in res.replace('@', '_').split(sep='_') if s.isdigit()]\n",
    "    doc_ids = np.array_split(doc_ids, batch_size)\n",
    "    for q_id, relevant_docs, predicted_list in zip(ids, target_texts, doc_ids):\n",
    "        for i, doc_id in enumerate(predicted_list):\n",
    "            if doc_id in relevant_docs:\n",
    "                doc_id_to_valid_queries.setdefault(doc_id, [])\n",
    "                doc_id_to_valid_queries[doc_id].append(q_id)\n",
    "                queries_to_correct_predicted_ids.setdefault(q_id, {})\n",
    "                queries_to_correct_predicted_ids[q_id][i + 1] = doc_id\n",
    "ids_with_more_than_threshold_correct_queries = {key: value for key, value in doc_id_to_valid_queries.items() if len(value) >= THRESHOLD}\n",
    "correct_queries_ids = set([q_id for key, query_list in ids_with_more_than_threshold_correct_queries.items() for q_id in query_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a519b47",
   "metadata": {
    "id": "DsQfHADYUdec"
   },
   "outputs": [],
   "source": [
    "torch.save(doc_id_to_valid_queries, 'doc_id_to_valid_queries.json')\n",
    "torch.save(queries_to_correct_predicted_ids, 'queries_to_correct_predicted_ids.json')\n",
    "torch.save(ids_with_more_than_threshold_correct_queries, 'ids_with_more_than_threshold_correct_queries.json')\n",
    "torch.save(correct_queries_ids, 'correct_queries_ids.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf9dc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xGb4SsSMh7Q",
    "outputId": "6c87f013-50c5-48d9-ba93-6f0a497529af"
   },
   "outputs": [],
   "source": [
    "correct_queries_at_first_place = set([q_id for q_id, q_dict in queries_to_correct_predicted_ids.items() if 1 in q_dict and q_id in correct_queries_ids])\n",
    "print(len(correct_queries_at_first_place))\n",
    "torch.save(correct_queries_at_first_place, 'correct_queries_at_first_place.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e58080",
   "metadata": {},
   "source": [
    "### Generating Activation Dictionaries by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd001fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nOnWE-FFsA4d",
    "outputId": "efb545e5-64ef-45f0-8251-8b951222048f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "for layer in range(17, 24):\n",
    "    ids = list(correct_queries_at_first_place)\n",
    "    queries = [q_id_to_entry[q_id]['query'] for q_id in ids]\n",
    "    truths = [q_id_to_entry[q_id]['relevant_docs'] for q_id in ids]\n",
    "    print(f'layer {layer}')\n",
    "    correct_dataset = QuestionsDataset(queries, truths, ids)\n",
    "    dl = DataLoader(correct_dataset, batch_size=batch_size, shuffle=False, collate_fn=dataset.collate_fn)\n",
    "    hook_names = [f'decoder.{layer}.mlp.hook_pre', f'decoder.{layer}.mlp.hook_post', f'decoder.{layer}.hook_mlp_out']\n",
    "    decoder_input = torch.tensor([[0]])\n",
    "    layer_query_to_activations = {}\n",
    "    for input_texts, target_texts, ids in dl:\n",
    "        input_tokens = tokenizer(input_texts, return_tensors='pt', padding=True)['input_ids'].cuda()\n",
    "        _, cache = model.run_with_cache(input_tokens, decoder_input, names_filter=hook_names)\n",
    "        for pre_act_row, post_act_row, out_act_row, q_id in zip(cache[f'decoder.{layer}.mlp.hook_pre'], cache[f'decoder.{layer}.mlp.hook_post'], cache[f'decoder.{layer}.hook_mlp_out'], ids):\n",
    "            layer_query_to_activations[q_id] = {'pre': pre_act_row.squeeze(0).cpu(), 'post': post_act_row.squeeze(0).cpu(), 'out': out_act_row.squeeze(0).cpu()}\n",
    "        del cache\n",
    "    torch.save(layer_query_to_activations, f'layer_activations_no_test/layer_{layer}.json')\n",
    "    layer_query_to_activations.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
